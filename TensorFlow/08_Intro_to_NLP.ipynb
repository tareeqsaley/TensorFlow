{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_Intro_to_NLP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WTTfXN_cMXf",
        "outputId": "05241c09-8997-48cf-d7ff-29a8d2ca804e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.8.2+zzzcolab20220527125636.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.7.0%2Bzzzcolab20220506150900-cp37-cp37m-linux_x86_64.whl\n",
            "\u001b[K     | 665.5 MB 115.7 MB/s\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.26.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.46.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 27.4 MB/s \n",
            "\u001b[?25hCollecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (14.0.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0+zzzcolab20220506150900 tensorflow-estimator-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What we're going to cover"
      ],
      "metadata": {
        "id": "dKbHFOQxcPT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Downloading a text dataset\n",
        "* Visualizing text data\n",
        "* Converting text into numbers using tokenization\n",
        "* Turning our tokenized text into an embedding\n",
        "* Modelling a text dataset\n",
        "* Starting with a baseline (TF-IDF)\n",
        "* Building several deep learning text models\n",
        "* Dense, LSTM, GRU, Conv1D, Transfer learning\n",
        "* Comparing the performance of each our models\n",
        "* Combining our models into an ensemble\n",
        "* Saving and loading a trained model\n",
        "* Find the most wrong predictions"
      ],
      "metadata": {
        "id": "0UWw4W07dNYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Helper Functions"
      ],
      "metadata": {
        "id": "eU-20k1PdjyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szgwnnvigZ0O",
        "outputId": "dee7db06-9f31-40f2-dfd7-48d3ce8d7eaf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-29 04:45:04--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-06-29 04:45:05 (67.4 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "O43BjYWogd64"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download a text dataset\n",
        "\n",
        "Let's start by download a text dataset. We'll be using the Real or Not? datset from Kaggle which contains text-based Tweets about natural disasters.\n",
        "\n",
        "The Real Tweets are actually about diasters, for example:\n",
        "\n",
        "Jetstar and Virgin forced to cancel Bali flights again because of ash from Mount Raung volcano\n",
        "The Not Real Tweets are Tweets not about diasters (they can be on anything), for example:\n",
        "\n",
        "'Education is the most powerful weapon which you can use to change the world.' Nelson #Mandela #quote\n",
        "For convenience, the dataset has been downloaded from Kaggle (doing this requires a Kaggle account) and uploaded as a downloadable zip file.\n",
        "\n",
        ">🔑 Note: The original downloaded data has not been altered to how you would download it from Kaggle.\n"
      ],
      "metadata": {
        "id": "lvNqrOETghCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXg78w7Yg7Wp",
        "outputId": "bb76d028-58fd-4c0e-ab94-2edeaf12dcbc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-29 04:45:09--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.81.208, 172.217.1.208, 142.250.73.208, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.81.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2022-06-29 04:45:09 (114 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping `nlp_getting_started.zip` gives the following 3 .csv files:\n",
        "\n",
        "* `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
        "* `train.csv` - training samples of real and not real diaster Tweets.\n",
        "* `test.csv` - testing samples of real and not real diaster Tweets."
      ],
      "metadata": {
        "id": "gdE_l2gvg-aY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_UtUveShhWl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now, our text data samples are in the form of .csv files. For an easy way to make them visual, let's turn them into pandas DataFrame's."
      ],
      "metadata": {
        "id": "Zvb97j8chvI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn .csv files into pandas DataFrame's\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NUa5LtiYh2lP",
        "outputId": "d669d8c1-75e3-4409-b785-d937bcecbb65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2ad411c-1022-4ecb-bce8-da037d468bc4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2ad411c-1022-4ecb-bce8-da037d468bc4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2ad411c-1022-4ecb-bce8-da037d468bc4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2ad411c-1022-4ecb-bce8-da037d468bc4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z3BXsVmUh3LT",
        "outputId": "f116f600-fe99-407e-8ab4-7c7ef573781f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23e760d9-42a4-470c-a650-fb98389e403a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23e760d9-42a4-470c-a650-fb98389e403a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23e760d9-42a4-470c-a650-fb98389e403a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23e760d9-42a4-470c-a650-fb98389e403a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the training data has a \"target\" column.\n",
        "\n",
        "We're going to be writing code to find patterns (e.g. different combinations of words) in the \"text\" column of the training dataset to predict the value of the \"target\" column.\n",
        "\n",
        "The test dataset doesn't have a \"target\" column."
      ],
      "metadata": {
        "id": "2IGI9IF9h_kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The test data doesn't have a target (that's what we'd try to predict)\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NEQNJbK0ig9Q",
        "outputId": "c01964b4-2f35-4439-dfe0-d0ce6dabb194"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dd1814f-fbd6-4716-8bbb-ce399b7de742\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dd1814f-fbd6-4716-8bbb-ce399b7de742')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dd1814f-fbd6-4716-8bbb-ce399b7de742 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dd1814f-fbd6-4716-8bbb-ce399b7de742');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg_AbnqtitJC",
        "outputId": "6d955606-c81c-4427-8fc9-5dd1c346a1f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Since we have two target values, we're dealing with a binary classification problem.\n",
        "\n",
        "It's fairly balanced too, about 60% negative class (target = 0) and 40% positive class (target = 1).\n",
        "\n",
        "Where,\n",
        "\n",
        ">`1` = a real disaster Tweet\n",
        "\n",
        ">`0` = not a real disaster Tweet"
      ],
      "metadata": {
        "id": "OqUmcjHbizpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksrGzFbEjDiL",
        "outputId": "de7dd4cd-100e-414e-d790-459c9719b4d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abundance of test data, usually 80/20 split is fine"
      ],
      "metadata": {
        "id": "iEGOw_NqjMX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SDAU_t4jp4V",
        "outputId": "dd7deb5d-f44c-45f8-ccaa-782969c61a85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "#picthis http://t.co/br7gmMh5Ek ÛÓ And IÛªm off! Thank you so much #Toronto. It has been such a whirlwind of amazingness. So glad I finallÛ_\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@thetimepast @saalon I have childhood trauma more resolved than theirs. Actual trauma. Fricken babies.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Daily Reflections\n",
            "August 6\n",
            "DRIVEN\n",
            "Driven by a hundred forms of fear self-delusion self-seeking and self-pity... http://t.co/DXfqOu4kT2\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "I liked a @YouTube video from @dannyonpc http://t.co/PyVRPrNhOP Battlefield Hardline - 11 NEW WEAPONS - New map - Throwingknifes!\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Dear @POTUS In the name of humanityI apologized to #Hiroshima Survivors.R u ready to do so?#Japan #nuclearweapons http://t.co/TWykzN4rlC\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data into training and validation sets"
      ],
      "metadata": {
        "id": "KkUt1xQcjqbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Since the test set has no labels and we need a way to evalaute our trained models, we'll split off some of the training data and create a validation set.\n",
        "\n",
        "When our model trains (tries patterns in the Tweet samples), it'll only see data from the training set and we can see how it performs on unseen data using the validation set.\n",
        "\n",
        "We'll convert our splits from pandas Series datatypes to lists of strings (for the text) and lists of ints (for the labels) for ease of use later."
      ],
      "metadata": {
        "id": "pxM2hW6ckNtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42) # random state for reproducibility"
      ],
      "metadata": {
        "id": "DbMkFqnNknFY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5uzP4fUkn2E",
        "outputId": "1569bfbe-a763-4174-afb8-3dd67b2d0237"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irvgSrM7k21z",
        "outputId": "26682673-8fbf-414f-df31-7d30077b3430"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers"
      ],
      "metadata": {
        "id": "xlb9xQUsk768"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers:\n",
        "\n",
        "**Tokenization** - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "1. Using **word-level** tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n",
        "2. **Character-level tokenization**, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
        "3.**Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
        "\n",
        "**Embeddings** - An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "1. **Create your own embedding**- Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
        "2. Reuse a pre-learned embedding - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
      ],
      "metadata": {
        "id": "YBEI5HJslat0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text vectorization (tokenization)\n",
        "\n",
        "The `TextVectorization` layer takes the following parameters:\n",
        "\n",
        "*` max_tokens` - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n",
        "* `standardize` - Method for standardizing text. Default is \"lower_and_strip_punctuation\" which lowers text and removes all punctuation marks.\n",
        "* `split` - How to split text, default is \"whitespace\" which splits on spaces.\n",
        "* `ngrams` - How many words to contain per token split, for example, ngrams=2 splits tokens into continuous sequences of 2.\n",
        "*` output_mode` - How to output tokens, can be \"int\" (integer mapping), \"binary\" (one-hot encoding), \"count\" or \"tf-idf\". See documentation for more.\n",
        "*` output_sequence_length` - Length of tokenized sequence to output. For example, if output_sequence_length=150, all tokenized sequences will be 150 tokens long.\n",
        "* `pad_to_max_tokens` - Defaults to False, if True, the output feature axis will be padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens. Only valid in certain modes, see docs for more."
      ],
      "metadata": {
        "id": "kiJZ-hkGqNa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
        "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
        "\n",
        "# Use the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
        "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
      ],
      "metadata": {
        "id": "f1I7JYMOq9y1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've initialized a `TextVectorization` object with the default settings but let's customize it a little bit for our own use case.\n",
        "\n",
        "In particular, let's set values for `max_token`s and `output_sequence_length.`\n",
        "\n",
        "For max_tokens (the number of words in the vocabulary), multiples of 10,000 (10,000, 20,000, 30,000) or the exact number of unique words in your text (e.g. 32,179) are common values.\n",
        "\n",
        "For our use case, we'll use 10,000.\n",
        "\n",
        "And for the output_sequence_length we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
      ],
      "metadata": {
        "id": "vliviCoGrwFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whgwoGSesLWD",
        "outputId": "49d6a1f3-2dff-4c1f-a64a-385ad10971ee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "-yDSYbMAsL7J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "KHp0cko3sRHd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pathb_-ksfXh",
        "outputId": "e09e5966-dc50-4146-8ba2-3f0ba1975ed9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we try our text_vectorizer on a few random sentences?"
      ],
      "metadata": {
        "id": "Iw2W61_hspiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HKriElW00Fj",
        "outputId": "0b2ea775-5182-43e5-95dd-55564296a932"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Former Freedom Surf/Spa Razed to Make Way for New Homes http://t.co/EX6JzQJ3NI      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 952, 2454, 7903,  477,    5,  144,  147,   10,   50,  195,    1,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TweKm8Y402jF",
        "outputId": "408b1408-d259-47b4-e211-5772247ee2a3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an Embedding Using the Embedding Layer"
      ],
      "metadata": {
        "id": "fhw1FGSF1G3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an Embedding using an Embedding Layer\n",
        "We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather than just being static (e.g. 1 = I, 2 = love, 3 = TensorFlow), a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "We can see what an embedding of a word looks like by using the tf.keras.layers.Embedding layer.\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "\n",
        "* `input_dim` - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "* `input_length` - Length of sequences being passed to embedding layer.\n",
        "Knowing these, let's make an embedding layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "8lf1vrdp2v29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\") \n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvv-0-Vh3HbZ",
        "outputId": "d8ddbec7-fda2-4e1b-f6c8-b3751551b1cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f62d7bc8250>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excellent, notice how embedding is a TensorFlow layer? This is important because we can use it as part of a model, meaning its parameters (word representations) can be updated and improved as the model learns."
      ],
      "metadata": {
        "id": "61692jkw3TkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSvcmmUp3mYQ",
        "outputId": "7bb519b8-0bee-4ea9-ee72-8a5057f96993"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "WACKOS like #MicheleBachman predict the WORLD will SOON be OBLITERATED by a burning firey INFERNO but cant accept #GlobalWarming!! HELLO!!!      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.00640418,  0.01682251,  0.00195462, ...,  0.04359378,\n",
              "          0.04193902,  0.0012416 ],\n",
              "        [-0.03071752,  0.04972876, -0.01677845, ..., -0.03565687,\n",
              "          0.0019665 , -0.04666593],\n",
              "        [ 0.03439753, -0.02137036, -0.04002481, ..., -0.01126385,\n",
              "         -0.02075452, -0.02154907],\n",
              "        ...,\n",
              "        [-0.02280595,  0.04378835,  0.04515358, ..., -0.02526791,\n",
              "          0.00563388, -0.01470927],\n",
              "        [ 0.02825913, -0.03693267, -0.04402525, ..., -0.02885563,\n",
              "         -0.03234972, -0.02033558],\n",
              "        [ 0.01112027, -0.02055171,  0.0250339 , ...,  0.0140762 ,\n",
              "          0.00621351, -0.01795131]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpMRkLAZ3qP6",
        "outputId": "4a8a639f-1afa-48db-e734-5a061dca3405"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-0.00640418,  0.01682251,  0.00195462, -0.03352938,  0.04405266,\n",
              "       -0.03851814,  0.00149175,  0.02461456, -0.00086755,  0.0383161 ,\n",
              "       -0.03941747, -0.04108413,  0.03866457,  0.04693766, -0.03705329,\n",
              "        0.03713027, -0.01164728, -0.01496168,  0.04328063, -0.03559051,\n",
              "       -0.03948933, -0.00122237,  0.02830635, -0.0494219 , -0.00473925,\n",
              "        0.0185906 , -0.04443493,  0.00617117, -0.03494148, -0.04809414,\n",
              "       -0.01621503, -0.01370454, -0.0382251 , -0.00914737, -0.00739085,\n",
              "        0.03948393,  0.0489594 , -0.0283396 , -0.04380312,  0.00267646,\n",
              "       -0.00154066, -0.03798597,  0.02179739,  0.00488193,  0.02941428,\n",
              "        0.01133228, -0.02147579, -0.0228446 ,  0.03041137,  0.04153759,\n",
              "        0.03724631, -0.02031036,  0.03627517,  0.02785117,  0.04418415,\n",
              "       -0.00950921,  0.0195733 , -0.02571585, -0.03526436, -0.04323376,\n",
              "       -0.02038094,  0.0232881 ,  0.00864964, -0.02877491,  0.03783163,\n",
              "        0.00736835, -0.01351135,  0.04740312, -0.01120365, -0.03713553,\n",
              "        0.03941808, -0.00127833,  0.03257501, -0.03614364,  0.02450829,\n",
              "       -0.04741177,  0.02665165, -0.01206498, -0.04847709,  0.00824339,\n",
              "        0.03052659, -0.01419853, -0.04307041, -0.03036951,  0.01026416,\n",
              "        0.00150632, -0.04376356,  0.0256702 , -0.03897071,  0.03222111,\n",
              "       -0.00132227,  0.03298226,  0.04663927,  0.04477939, -0.00117246,\n",
              "        0.01461137,  0.02915258, -0.02392895, -0.00403708, -0.04678145,\n",
              "        0.04069054,  0.03769622,  0.03246384,  0.01024634,  0.00575604,\n",
              "        0.01643274,  0.00322719, -0.03099877,  0.01020645,  0.0182945 ,\n",
              "        0.02592644, -0.00413918, -0.02631878, -0.04428932,  0.04547827,\n",
              "        0.02766849, -0.0425388 , -0.01033986,  0.02827403,  0.00809131,\n",
              "        0.02634052,  0.0184615 ,  0.01579876, -0.01539649,  0.02640552,\n",
              "        0.04359378,  0.04193902,  0.0012416 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset\n",
        "\n",
        "Now that we've got a way to turn our text data into numbers, we can start to build machine learning models to model it.\n",
        "\n",
        "To get plenty of practice, we're going to build a series of different models, each as its own experiment. We'll then compare the results of each model and see which one performed best.\n",
        "\n",
        "More specifically, we'll be building the following:\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model\n",
        "* Model 3: GRU model\n",
        "* Model 4: Bidirectional-LSTM model\n",
        "* Model 5: 1D Convolutional Neural Network\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.\n",
        "\n"
      ],
      "metadata": {
        "id": "SflaEWRh35sa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: Getting a Baseline"
      ],
      "metadata": {
        "id": "P0SkPqMv4i_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMTIepZS4tHI",
        "outputId": "77d00e6e-f987-4406-df3d-a53eb7ee8bf5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The benefit of using a shallow model like Multinomial Naive Bayes is that training is very fast.\n",
        "\n",
        "Let's evaluate our model and find our baseline metric."
      ],
      "metadata": {
        "id": "gIZ0ErvE486r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZJ18t-_5Mp7",
        "outputId": "a4d2d885-bce3-40ed-923f-d9ffd22ac1d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an evaluation function for our model experiments\n",
        "We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "> 🔑 Note: Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice."
      ],
      "metadata": {
        "id": "1dX8FdKf5PVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall,f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model\n",
        "\n",
        "  Args:\n",
        "  y_true: true labels in the form of a 1-D array\n",
        "  y_pred = preddicted labels in the form of a 1-D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "\n",
        "  #Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f-1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average = \"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\":model_f1}\n",
        "  return model_results\n"
      ],
      "metadata": {
        "id": "LC8nO39H5wb4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results =  calculate_results(y_true = val_labels,\n",
        "                                      y_pred = baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6qvdIk19Qx7",
        "outputId": "1b974be6-30e0-4772-c814-c6cb146a8896"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: A Simple Dense Model"
      ],
      "metadata": {
        "id": "RuxloVDz95kO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first \"deep\" model we're going to build is a single layer dense model. In fact, it's barely going to have a single layer.\n",
        "\n",
        "It'll take our text and labels as input, tokenize the text, create an embedding, find the average of the embedding (using Global Average Pooling) and then pass the average through a fully connected layer with one output unit and a sigmoid activation function.\n",
        "\n",
        "If the previous sentence sounds like a mouthful, it'll make sense when we code it out (remember, if in doubt, code it out).\n",
        "\n",
        "And since we're going to be building a number of TensorFlow deep learning models, we'll import our `create_tensorboard_callback()` function from helper_functions.py to keep track of the results of each."
      ],
      "metadata": {
        "id": "mgBfZHVZ-Vxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "aWMeWvI4-ZTw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,),dtype=\"string\") #inputs are 1D strings\n",
        "x = text_vectorizer(inputs) #Turn the input text into numbers\n",
        "x = embedding(x) #Create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) #Reduce the dimensionality of the embedding\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") #construct the model\n",
        "\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "8shsn7tQ-xl7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8soXU0VBHmA",
        "outputId": "011de006-f22a-4fc0-f4e7-5a75bce16c5b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the trainable parameters are contained within the embedding layer. Recall we created an embedding of size 128 (output_dim=128) for a vocabulary of size 10,000 (input_dim=10000), hence the 1,280,000 trainable parameters."
      ],
      "metadata": {
        "id": "uucz4eF1CQuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GenRZ__NCm52",
        "outputId": "4ebf3d01-7412-4e80-b731-afac82267da5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20220629-044511\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 19ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 28ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 30ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px1E3i28Cq_J",
        "outputId": "2f87df3c-95c5-4aff-e456-3c4860b9cfd1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4766846001148224, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embedding.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHPizHx-Cx43",
        "outputId": "4a9db6c4-4154-4a52-814c-974f3b27974a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
              " array([[ 0.00073164,  0.01504797, -0.03425453, ..., -0.04403542,\n",
              "         -0.01042278,  0.01876436],\n",
              "        [ 0.04135864, -0.03945082, -0.03811938, ...,  0.00464735,\n",
              "          0.03163553,  0.02928304],\n",
              "        [ 0.00684034,  0.05363134, -0.00241555, ..., -0.07082174,\n",
              "         -0.04750701,  0.01448254],\n",
              "        ...,\n",
              "        [-0.03301444, -0.0052493 , -0.04209725, ...,  0.02028764,\n",
              "          0.00308807,  0.02215792],\n",
              "        [ 0.00692342,  0.05942352, -0.01975194, ..., -0.06199061,\n",
              "         -0.01018394,  0.03510419],\n",
              "        [-0.03723461,  0.06267188, -0.07451147, ..., -0.02367217,\n",
              "         -0.08643329,  0.01742156]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQmPV_vfC6cn",
        "outputId": "3d6f2f1a-892f-4d38-a5c4-8e6240d334ef"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Make predictions (these come back in the form of probabilities)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAKPvpNzDBTU",
        "outputId": "04c0d9a7-f4e6-4bb8-84d2-12541ab701d1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40488204],\n",
              "       [0.7443311 ],\n",
              "       [0.997895  ],\n",
              "       [0.10889998],\n",
              "       [0.11143529],\n",
              "       [0.93556094],\n",
              "       [0.9134594 ],\n",
              "       [0.99253446],\n",
              "       [0.9715681 ],\n",
              "       [0.26570344]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
        "model_1_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGPUnhU7Dozt",
        "outputId": "f8b2257a-9921-41f2-c788-9bc0a6fc9b96"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8D9Wr9lDxlm",
        "outputId": "0a0aec44-16da-4ff0-e3c4-055b6933b043"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'f1': 0.7846966492209201,\n",
              " 'precision': 0.7914920592553047,\n",
              " 'recall': 0.7874015748031497}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
        "                                new_model_results=model_1_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_J4cawVD4XG",
        "outputId": "ed21274d-6180-46d6-f96c-e1c50abdf629"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks (RNN's)"
      ],
      "metadata": {
        "id": "p5UzpTXID_Bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our next series of modelling experiments we're going to be using a special kind of neural network called a Recurrent Neural Network (RNN).\n",
        "\n",
        "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
        "\n",
        "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
        "\n",
        "For example, when you read this sentence, you take into context the previous words when deciphering the meaning of the current word dog.\n",
        "\n",
        "See what happened there?\n",
        "\n",
        "I put the word \"dog\" at the end which is a valid word but it doesn't make sense in the context of the rest of the sentence.\n",
        "\n",
        "When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence.\n",
        "\n",
        "For a simple example, take two sentences:\n",
        "\n",
        "1. Massive earthquake last week, no?\n",
        "2. No massive earthquake last week.\n",
        "\n",
        "Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n",
        "\n",
        "Recurrent neural networks can be used for a number of sequence-based problems:\n",
        "\n",
        "* **One to one:** one input, one output, such as image classification.\n",
        "* **One to many:** one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "* **Many to one:** many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "* **Many to many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
        "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
        "\n",
        "Long short-term memory cells (LSTMs).\n",
        "Gated recurrent units (GRUs).\n",
        "Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n",
        "Going into the details of each these is beyond the scope of this notebook (we're going to focus on using them instead), the main thing you should know for now is that they've proven very effective at modelling sequences."
      ],
      "metadata": {
        "id": "FpxAJ4GKFBf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: LSTM"
      ],
      "metadata": {
        "id": "p7OdYktLFtcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n",
        "\n",
        "# Compile model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJBw3GGXF_ge",
        "outputId": "da5e9f74-44b4-43f9-9ad3-6974ff8ea4a6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n",
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"LSTM\")])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM69wbEbGbSx",
        "outputId": "1d8cdf1f-835d-4373-ad7c-edccc7befb05"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20220629-044553\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 35ms/step - loss: 0.5100 - accuracy: 0.7416 - val_loss: 0.4566 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 26ms/step - loss: 0.3176 - accuracy: 0.8717 - val_loss: 0.5138 - val_accuracy: 0.7756\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 25ms/step - loss: 0.2201 - accuracy: 0.9152 - val_loss: 0.5858 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 30ms/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.6041 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.8746 - val_accuracy: 0.7507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9oOVC3oGneb",
        "outputId": "dfb712cd-461c-4199-a9ee-368779f63dcf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[0.00712615],\n",
              "        [0.7873689 ],\n",
              "        [0.9996376 ],\n",
              "        [0.05679163],\n",
              "        [0.00258216],\n",
              "        [0.99962384],\n",
              "        [0.9217019 ],\n",
              "        [0.9997994 ],\n",
              "        [0.99949545],\n",
              "        [0.66457486]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can turn these prediction probabilities into prediction classes by rounding to the nearest integer (by default, prediction probabilities under 0.5 will go to 0 and those over 0.5 will go to 1)."
      ],
      "metadata": {
        "id": "c7UAJ-aKGrUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgUbO5qbGuKJ",
        "outputId": "0bfe378b-95ab-4139-a4e8-09f91ccd7582"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsGMdteIGycU",
        "outputId": "2eac3f03-3e6e-4b4a-8044-714fee8ae648"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.06561679790026,\n",
              " 'f1': 0.7489268622514025,\n",
              " 'precision': 0.7510077975908164,\n",
              " 'recall': 0.7506561679790026}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GwmVdauG4NB",
        "outputId": "574ebd5e-7590-45e8-cec4-8da42cf59b81"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 75.07, Difference: -4.20\n",
            "Baseline precision: 0.81, New precision: 0.75, Difference: -0.06\n",
            "Baseline recall: 0.79, New recall: 0.75, Difference: -0.04\n",
            "Baseline f1: 0.79, New f1: 0.75, Difference: -0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit."
      ],
      "metadata": {
        "id": "SCDu59EBHCHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x) \n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n",
        "\n",
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of the GRU model\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQTfApAaIr6A",
        "outputId": "d9664662-1117-4a29-f9b8-4b78558b3b4b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZFuVadXI64x",
        "outputId": "d46e7a37-1d58-435e-ed62-987734dd2d9a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20220629-044628\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 32ms/step - loss: 0.5242 - accuracy: 0.7314 - val_loss: 0.4553 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.3195 - accuracy: 0.8694 - val_loss: 0.4937 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.2197 - accuracy: 0.9181 - val_loss: 0.5607 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.1599 - accuracy: 0.9441 - val_loss: 0.6220 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.1221 - accuracy: 0.9584 - val_loss: 0.6205 - val_accuracy: 0.7677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjwQn9Z5JEsd",
        "outputId": "87db8139-103f-4a00-d9aa-39161d9c178d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[0.333252  ],\n",
              "        [0.877412  ],\n",
              "        [0.9980252 ],\n",
              "        [0.11561716],\n",
              "        [0.01235956],\n",
              "        [0.9925637 ],\n",
              "        [0.6214276 ],\n",
              "        [0.9981333 ],\n",
              "        [0.9982377 ],\n",
              "        [0.50181204]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7p8q9rrBzA3",
        "outputId": "175a9519-001b-4221-c755-b891e116b170"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmudIP5pJKd-",
        "outputId": "c3a23a13-472d-425a-8f1a-c0756bd06379"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'f1': 0.7667932666650168,\n",
              " 'precision': 0.7675450859410361,\n",
              " 'recall': 0.7677165354330708}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgujCvzmJNwA",
        "outputId": "65e2028f-2242-4764-fda7-d523e912f3d0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.77, Difference: -2.49\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Bidirectonal RNN model"
      ],
      "metadata": {
        "id": "2RHhTQoZJR31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "Intuitively, this can be thought of as if you were reading a sentence for the first time in the normal fashion (left to right) but for some reason it didn't make sense so you traverse back through the words and go back over them again (right to left).\n",
        "\n",
        "In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
        "\n",
        "However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles).\n",
        "\n",
        "Okay enough talk, let's build a bidirectional RNN."
      ],
      "metadata": {
        "id": "igU63H-PJs-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ],
      "metadata": {
        "id": "LEmHQPj_JwMT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "_UiPtEvWJxLG"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()\n",
        "Model: \"model_4_Bidirectional\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7vkWkjwJ2Kx",
        "outputId": "b0e93ab1-6efd-4b08-afc1-e3319c41936d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the increased number of trainable parameters in model_4 (bidirectional LSTM) compared to model_2 (regular LSTM). This is due to the bidirectionality we added to our RNN.\n",
        "\n",
        "Time to fit our bidirectional model and track its performance."
      ],
      "metadata": {
        "id": "gW_QwktDJ4be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0TgCh01KABi",
        "outputId": "44a38ca1-6f42-4d6a-d6b8-e94be9b5939b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20220629-055610\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 26s 88ms/step - loss: 0.5093 - accuracy: 0.7481 - val_loss: 0.4606 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 16s 72ms/step - loss: 0.3135 - accuracy: 0.8708 - val_loss: 0.5144 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 11s 51ms/step - loss: 0.2150 - accuracy: 0.9178 - val_loss: 0.5626 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.1523 - accuracy: 0.9469 - val_loss: 0.6365 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.1083 - accuracy: 0.9639 - val_loss: 0.6509 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQZ7W-wBKD0H",
        "outputId": "cbac2ce0-c34a-442a-b53d-2c08a3fd3889"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04000095],\n",
              "       [0.82792675],\n",
              "       [0.99842227],\n",
              "       [0.13531172],\n",
              "       [0.00311336],\n",
              "       [0.9922074 ],\n",
              "       [0.9552848 ],\n",
              "       [0.9994564 ],\n",
              "       [0.99898285],\n",
              "       [0.28141806]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKbTTdvtKHuc",
        "outputId": "bb71e4d7-1080-436a-a7ad-8db1516a0dd2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBYTV4ZlKZ3u",
        "outputId": "b2ad4718-6ef7-4bb6-be2c-df91c02efb53"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'f1': 0.7651213533864446,\n",
              " 'precision': 0.7665895370389821,\n",
              " 'recall': 0.7664041994750657}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see how the bidirectional model performs against the baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoQIjft8N3ZF",
        "outputId": "0f199822-3d7b-4a57-b6c8-8f78e6796ad1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.64, Difference: -2.62\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks for Text"
      ],
      "metadata": {
        "id": "55JvW0zZOXnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might've used convolutional neural networks (CNNs) for images before but they can also be used for sequences.\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
        "\n",
        "A typical CNN architecture for sequences will look like the following:\n",
        "\n",
        "`Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)`\n",
        "\n",
        "You might be thinking \"that just looks like the architecture layout we've been using for the other models...\"\n",
        "\n",
        "And you'd be right.\n",
        "\n",
        "The difference again is in the layers component. Instead of using an LSTM or GRU cell, we're going to use a `tensorflow.keras.layers.Conv1D()` layer followed by a `tensorflow.keras.layers.GlobablMaxPool1D()` layer."
      ],
      "metadata": {
        "id": "PCRAryhPN6ST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "Before we build a full 1-dimensional CNN model, let's see a 1-dimensional convolutional layer (also called a temporal convolution) in action."
      ],
      "metadata": {
        "id": "ImFJV7-HPBjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalMaxPool1D() \n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_MD7rwsPUnG",
        "outputId": "5057ce93-7230-43b1-e0f1-443d5b256ff0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "\n",
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our 1D convolution model\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvDJfOCLPVlo",
        "outputId": "73db298e-0a79-44bc-e9ac-cd37dfaa8ff3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2-q2rxaB9sw",
        "outputId": "d691c79b-eae0-445b-c7f5-693d331bef82"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20220629-055942\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 36ms/step - loss: 0.5652 - accuracy: 0.7141 - val_loss: 0.4733 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.3380 - accuracy: 0.8615 - val_loss: 0.4758 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.2070 - accuracy: 0.9234 - val_loss: 0.5457 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.1314 - accuracy: 0.9578 - val_loss: 0.6163 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0933 - accuracy: 0.9691 - val_loss: 0.6779 - val_accuracy: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dr7dxbhCxVz",
        "outputId": "f2e05f90-4f07-4de9-eaa2-ed426c841346"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22534508],\n",
              "       [0.75341123],\n",
              "       [0.99956024],\n",
              "       [0.05562782],\n",
              "       [0.01449853],\n",
              "       [0.98585176],\n",
              "       [0.9841893 ],\n",
              "       [0.99758804],\n",
              "       [0.9986262 ],\n",
              "       [0.26914358]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQfgtR7SC6cm",
        "outputId": "bc98dc59-0acc-420d-9f95-fcf677812822"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLiYT8ooC9_i",
        "outputId": "04871e54-11f1-40d3-cd57-c434036e4149"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'f1': 0.7758810170952618,\n",
              " 'precision': 0.7807522349051432,\n",
              " 'recall': 0.7782152230971129}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model_5 results to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIoSbQoTDBgp",
        "outputId": "c5c14731-4d2c-4eb2-9af4-7d787a5c2aa4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.82, Difference: -1.44\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using Pretrained Embeddings (transfer learning for NLP)"
      ],
      "metadata": {
        "id": "s9RYlXeCDEsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " For all of the previous deep learning models we've built and trained, we've created and used our own embeddings from scratch each time.\n",
        "\n",
        "However, a common practice is to leverage pretrained embeddings through transfer learning. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "\n",
        "For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n",
        "\n",
        "More specifically, we're going to be using the Universal Sentence Encoder from TensorFlow Hub (a great resource containing a plethora of pretrained model resources for a variety of tasks)."
      ],
      "metadata": {
        "id": "MN12QCuGDVku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model 6: TensorFlow Hub Pretrained Sentence Encoder"
      ],
      "metadata": {
        "id": "YdTOxqG5Dlo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference between the embedding layer we created and the Universal Sentence Encoder is that rather than create a word-level embedding, the Universal Sentence Encoder, as you might've guessed, creates a whole sentence-level embedding.\n",
        "\n",
        "Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence."
      ],
      "metadata": {
        "id": "2_jesdIeDu32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JItXCw4iD6BM",
        "outputId": "96ff5783-e953-42dc-e161-a561d67a243e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157025  0.02485911  0.02878051 -0.012715    0.03971541  0.08827761\n",
            "  0.02680988  0.05589839 -0.01068731 -0.00597293  0.00639321 -0.01819516\n",
            "  0.00030816  0.09105889  0.05874646 -0.03180629  0.01512474 -0.05162925\n",
            "  0.00991366 -0.06865345 -0.04209306  0.0267898   0.03011009  0.00321065\n",
            " -0.00337968 -0.04787357  0.0226672  -0.00985927 -0.04063615 -0.01292093\n",
            " -0.04666382  0.05630299 -0.03949255  0.00517682  0.02495827 -0.07014439\n",
            "  0.0287151   0.0494768  -0.00633978 -0.08960193  0.02807119 -0.00808364\n",
            " -0.01360601  0.05998649 -0.10361788 -0.05195373  0.00232958 -0.02332531\n",
            " -0.03758106  0.03327729], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_R4d3kLEPEn",
        "outputId": "46706aa9-61f6-4f2a-84de-2aede21bcff1"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\") "
      ],
      "metadata": {
        "id": "ExG3AKkdEkg2"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bLOUaLLEowh",
        "outputId": "81dcebbe-e363-41a1-fa51-76a8a65a6b5a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the number of paramters in the USE layer, these are the pretrained weights its learned on various text sources (Wikipedia, web news, web question-answer forums, etc, see the Universal Sentence Encoder paper for more).\n",
        "\n",
        "The trainable parameters are only in our output layers, in other words, we're keeping the USE weights frozen and using it as a feature-extractor. We could fine-tune these weights by setting trainable=True when creating the hub.KerasLayer instance.\n",
        "\n",
        "Now we've got a feature extractor model ready, let's train it and track its results to TensorBoard using our create_tensorboard_callback() function.\n"
      ],
      "metadata": {
        "id": "fC99z8-5EwIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxRfKPxQE8RZ",
        "outputId": "f20801fe-14a2-446c-8821-488a2bc4d00f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.502315  ],\n",
              "       [0.51316595],\n",
              "       [0.5206348 ],\n",
              "       [0.5194472 ],\n",
              "       [0.50981855],\n",
              "       [0.51598704],\n",
              "       [0.5117805 ],\n",
              "       [0.5196754 ],\n",
              "       [0.5050281 ],\n",
              "       [0.5078458 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk9nY7ATFJSr",
        "outputId": "7311d89e-1187-41de-e2e7-97f92fb15c7f"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVJIWmSzFQuq",
        "outputId": "b4f8fa3c-0be7-4a36-c096-5b92d46c7e9a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 50.39370078740157,\n",
              " 'f1': 0.4604966997867244,\n",
              " 'precision': 0.5497426557145474,\n",
              " 'recall': 0.5039370078740157}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare TF Hub model to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RouvsR5XFS_k",
        "outputId": "41a31c6a-42fb-4acc-f689-4b1d9724845b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 50.39, Difference: -28.87\n",
            "Baseline precision: 0.81, New precision: 0.55, Difference: -0.26\n",
            "Baseline recall: 0.79, New recall: 0.50, Difference: -0.29\n",
            "Baseline f1: 0.79, New f1: 0.46, Difference: -0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model 7: TensorFlow Hub Pretrained Sentence Encoder 10% of the training data"
      ],
      "metadata": {
        "id": "XkyYVQXYF9BL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the benefits of using transfer learning methods, such as, the pretrained embeddings within the USE is the ability to get great results on a small amount of data (the USE paper even mentions this in the abstract)."
      ],
      "metadata": {
        "id": "TSNOSqcEGJy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# One kind of correct way (there are more) to make data subset\n",
        "# (split the already split train_sentences/train_labels)\n",
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=42)\n"
      ],
      "metadata": {
        "id": "YADq7SkmGX9L"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check length of 10 percent datasets\n",
        "print(f\"Total training examples: {len(train_sentences)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAg5NVLnGeUS",
        "outputId": "53366a47-0657-4dc8-9174-a203d0e2f1f6"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training examples: 6851\n",
            "Length of 10% training examples: 686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of targets in our subset of data \n",
        "# (this should be close to the distribution of labels in the original train_labels)\n",
        "pd.Series(train_labels_10_percent).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UauPuLmGoZw",
        "outputId": "e0ba72ce-7b9c-44b7-eecc-d0e9367dc951"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    415\n",
              "1    271\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone model_6 but reset weights\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiATVQ-dGszy",
        "outputId": "6b1b23a4-37df-453b-97b1-851857615e72"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Notice the layout of model_7 is the same as model_6. Now let's train the newly created model on our 10% training data subset.\n",
        "\n",
        "# Fit the model to 10% of the training data\n",
        "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
        "                              y=train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5olWY812GvuT",
        "outputId": "550470b5-5864-4b35-acf0-6d50d60ec5c6"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20220629-061731\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 7s 52ms/step - loss: 0.6677 - accuracy: 0.6676 - val_loss: 0.6514 - val_accuracy: 0.6693\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6004 - accuracy: 0.7901 - val_loss: 0.5985 - val_accuracy: 0.7310\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.5261 - accuracy: 0.8178 - val_loss: 0.5450 - val_accuracy: 0.7559\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.4610 - accuracy: 0.8280 - val_loss: 0.5107 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.4163 - accuracy: 0.8367 - val_loss: 0.4924 - val_accuracy: 0.7769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7AJeYcTG0jp",
        "outputId": "aeef5e4c-6f5a-483f-87e9-0bfb79f024a1"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.26266134],\n",
              "       [0.78521055],\n",
              "       [0.8816253 ],\n",
              "       [0.28732795],\n",
              "       [0.5858127 ],\n",
              "       [0.82047284],\n",
              "       [0.80415213],\n",
              "       [0.8412341 ],\n",
              "       [0.80571204],\n",
              "       [0.1395225 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L8lZzK6G6rK",
        "outputId": "8339d00d-77ed-4c41-a8e8-a57bc5bb6ef5"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate model results\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQu0G-F5HCX8",
        "outputId": "3fced894-c23a-43c9-f449-668198b44e30"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.69028871391076,\n",
              " 'f1': 0.7739165030429329,\n",
              " 'precision': 0.7809693289921038,\n",
              " 'recall': 0.7769028871391076}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_7_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ailk12kwHGL5",
        "outputId": "249e64ba-495d-4f1e-d373-739f9dd13501"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.69, Difference: -1.57\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing the performance of each of our models"
      ],
      "metadata": {
        "id": "lKEB3LHZHJtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woah. We've come a long way! From training a baseline to several deep models.\n",
        "\n",
        "Now it's time to compare our model's results.\n",
        "\n",
        "But just before we do, it's worthwhile mentioning, this type of practice is a standard deep learning workflow. Training various different models, then comparing them to see which one performed best and continuing to train it if necessary.\n",
        "\n",
        "The important thing to note is that for all of our modelling experiments we used the same training data (except for model_7 where we used 10% of the training data).\n",
        "\n",
        "To visualize our model's performances, let's create a pandas DataFrame we our results dictionaries and then plot it."
      ],
      "metadata": {
        "id": "IrYXyChAHaL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
        "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "PnoeOkW8Hd3B",
        "outputId": "5e4b4f77-0650-4cec-fdb2-a45755db2687"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 79.265092   0.811139  0.792651  0.786219\n",
              "simple_dense             78.740157   0.791492  0.787402  0.784697\n",
              "lstm                     75.065617   0.751008  0.750656  0.748927\n",
              "gru                      76.771654   0.767545  0.767717  0.766793\n",
              "bidirectional            76.640420   0.766590  0.766404  0.765121\n",
              "conv1d                   77.821522   0.780752  0.778215  0.775881\n",
              "tf_hub_sentence_encoder  50.393701   0.549743  0.503937  0.460497\n",
              "tf_hub_10_percent_data   77.690289   0.780969  0.776903  0.773917"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b480ae3f-1f4f-446b-bf43-46fb33067dbf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>78.740157</td>\n",
              "      <td>0.791492</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.784697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>75.065617</td>\n",
              "      <td>0.751008</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.748927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>76.771654</td>\n",
              "      <td>0.767545</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.766793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>76.640420</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>50.393701</td>\n",
              "      <td>0.549743</td>\n",
              "      <td>0.503937</td>\n",
              "      <td>0.460497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>77.690289</td>\n",
              "      <td>0.780969</td>\n",
              "      <td>0.776903</td>\n",
              "      <td>0.773917</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b480ae3f-1f4f-446b-bf43-46fb33067dbf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b480ae3f-1f4f-446b-bf43-46fb33067dbf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b480ae3f-1f4f-446b-bf43-46fb33067dbf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "92GQDqzUHebB"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "HwD9O0x6HlO3",
        "outputId": "401f2fd8-f7fc-4150-db87-4be71ee1a8df"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "ele3yAReHoI2",
        "outputId": "a716af2f-bdbc-4305-ea03-5548731a6893"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining our models (model ensembling/stacking)"
      ],
      "metadata": {
        "id": "wb2w6V6aHses"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many production systems use an ensemble (multiple different models combined) of models to make a prediction.\n",
        "\n",
        "The idea behind model stacking is that if several uncorrelated models agree on a prediction, then the prediction must be more robust than a prediction made by a singular model.\n",
        "\n",
        "The keyword in the sentence above is uncorrelated, which is another way of saying, different types of models. For example, in our case, we might combine our baseline, our bidirectional model and our TensorFlow Hub USE model.\n",
        "\n",
        "Although these models are all trained on the same data, they all have a different way of finding patterns.\n",
        "\n",
        "If we were to use three similarly trained models, such as three LSTM models, the predictions they output will likely be very similar.\n",
        "\n",
        "Think of it as trying to decide where to eat with your friends. If you all have similar tastes, you'll probably all pick the same restaurant. But if you've all got different tastes and still end up picking the same restaurant, the restaurant must be good.\n",
        "\n",
        "Since we're working with a classification problem, there are a few of ways we can combine our models:\n",
        "\n",
        "**1. Averaging** - Take the output prediction probabilities of each model for each sample, combine them and then average them.\n",
        "\n",
        "**2. Majority vote (mode)** - Make class predictions with each of your models on all samples, the predicted class is the one in majority. For example, if three different models predict [1, 0, 1] respectively, the majority class is 1, therefore, that would be the predicted label.\n",
        "\n",
        "**3. Model stacking** - Take the outputs of each of your chosen models and use them as inputs to another model."
      ],
      "metadata": {
        "id": "KvtFG4-QH9F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get mean pred probs for 3 models\n",
        "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
        "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_1_pred_probs)\n",
        "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
        "combined_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uohxGBRiIPub",
        "outputId": "14d4c897-60ac-40b0-e3f7-5d3e6b389f7d"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wonderful! We've got a combined predictions array of different classes, let's evaluate them against the true labels and add our stacked model's results to our all_model_results DataFrame."
      ],
      "metadata": {
        "id": "tmBnAyxyIwX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results from averaging the prediction probabilities\n",
        "ensemble_results = calculate_results(val_labels, combined_preds)\n",
        "ensemble_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ628Ta-Iyzn",
        "outputId": "bda760b5-9a3c-489a-8ad7-ac5a83a413d6"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 74.93438320209974,\n",
              " 'f1': 0.7484479483637092,\n",
              " 'precision': 0.7489330230482325,\n",
              " 'recall': 0.7493438320209974}"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add our combined model's results to the results DataFrame\n",
        "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
      ],
      "metadata": {
        "id": "ZjUmIzM2I3DA"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the accuracy to the same scale as the rest of the results\n",
        "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "eeKQ1pSiI7z0"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "9NDQrfHkI-aY",
        "outputId": "30f28074-09cc-4b98-a400-6d941cd4e8d5"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         accuracy  precision    recall        f1\n",
              "baseline                 0.792651   0.811139  0.792651  0.786219\n",
              "simple_dense             0.787402   0.791492  0.787402  0.784697\n",
              "lstm                     0.750656   0.751008  0.750656  0.748927\n",
              "gru                      0.767717   0.767545  0.767717  0.766793\n",
              "bidirectional            0.766404   0.766590  0.766404  0.765121\n",
              "conv1d                   0.778215   0.780752  0.778215  0.775881\n",
              "tf_hub_sentence_encoder  0.503937   0.549743  0.503937  0.460497\n",
              "tf_hub_10_percent_data   0.776903   0.780969  0.776903  0.773917\n",
              "ensemble_results         0.749344   0.748933  0.749344  0.748448"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52d88ff8-680e-4812-9142-d58786c83e93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.791492</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.784697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.751008</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.748927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.767545</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.766793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>0.503937</td>\n",
              "      <td>0.549743</td>\n",
              "      <td>0.503937</td>\n",
              "      <td>0.460497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>0.776903</td>\n",
              "      <td>0.780969</td>\n",
              "      <td>0.776903</td>\n",
              "      <td>0.773917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_results</th>\n",
              "      <td>0.749344</td>\n",
              "      <td>0.748933</td>\n",
              "      <td>0.749344</td>\n",
              "      <td>0.748448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52d88ff8-680e-4812-9142-d58786c83e93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52d88ff8-680e-4812-9142-d58786c83e93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52d88ff8-680e-4812-9142-d58786c83e93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the most wrong examples"
      ],
      "metadata": {
        "id": "RsC-L8idJAfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e mentioned before that if many of our modelling experiments are returning similar results, despite using different kinds of models, it's a good idea to return to the data and inspect why this might be.\n",
        "\n",
        "One of the best ways to inspect your data is to sort your model's predictions and find the samples it got most wrong, meaning, what predictions had a high prediction probability but turned out to be wrong.\n",
        "\n",
        "Once again, visualization is your friend. Visualize, visualize, visualize.\n",
        "\n",
        "To make things visual, let's take our best performing model's prediction probabilities and classes along with the validation samples (text and ground truth labels) and combine them in a pandas DataFrame.\n",
        "\n",
        "* If our best model still isn't perfect, what examples is it getting wrong?\n",
        "* Which ones are the most wrong?\n",
        "* Are there some labels which are wrong? E.g. the model gets it right but the ground truth label doesn't reflect this"
      ],
      "metadata": {
        "id": "ESy8U9eCJma9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe with validation sentences and best performing model predictions\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NU43cr2AJ22O",
        "outputId": "63a267fe-22d7-4071-b34d-c44d6d7db81d"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   1.0   0.502315\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.513166\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.520635\n",
              "3  @camilacabello97 Internally and externally scr...       1   1.0   0.519447\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.509819"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85dce5e9-7289-42a9-9774-3064ef523f79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.502315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.513166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.520635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.519447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.509819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85dce5e9-7289-42a9-9774-3064ef523f79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85dce5e9-7289-42a9-9774-3064ef523f79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85dce5e9-7289-42a9-9774-3064ef523f79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "tNwRGIP-J5bT",
        "outputId": "041ca127-7a88-4790-fcb4-192986f3aed6"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "716  Crackdown 3 Destruction Restricted to Multipla...       0   1.0   \n",
              "729  Crackdown 3 Destruction Restricted to Multipla...       0   1.0   \n",
              "520            Wrinkled the face of deluge as decayed;       0   1.0   \n",
              "568  Untangle yourself from requiring your partner ...       0   1.0   \n",
              "682  A change in the State fire code prohibits gril...       0   1.0   \n",
              "33   #ArrestpastorNganga it so worrying 2 see how s...       0   1.0   \n",
              "546  Enugu Government to demolish illegal structure...       0   1.0   \n",
              "654      Armageddon averted by El Patron\\n#UltimaLucha       0   1.0   \n",
              "574  Your PSA for the day: If a fire truck is behin...       0   1.0   \n",
              "37             @almusafirah_ you feel trapped innit ??       0   1.0   \n",
              "\n",
              "     pred_prob  \n",
              "716   0.547264  \n",
              "729   0.545132  \n",
              "520   0.544498  \n",
              "568   0.543779  \n",
              "682   0.541711  \n",
              "33    0.539081  \n",
              "546   0.538071  \n",
              "654   0.537201  \n",
              "574   0.536670  \n",
              "37    0.536466  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-801c4c0d-d89b-4b5c-9b80-85cc8efc9897\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>Crackdown 3 Destruction Restricted to Multipla...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.547264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>Crackdown 3 Destruction Restricted to Multipla...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.545132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>Wrinkled the face of deluge as decayed;</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.544498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>Untangle yourself from requiring your partner ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.543779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>A change in the State fire code prohibits gril...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.541711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>#ArrestpastorNganga it so worrying 2 see how s...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.539081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>Enugu Government to demolish illegal structure...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.538071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654</th>\n",
              "      <td>Armageddon averted by El Patron\\n#UltimaLucha</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.537201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>Your PSA for the day: If a fire truck is behin...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.536670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>@almusafirah_ you feel trapped innit ??</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.536466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-801c4c0d-d89b-4b5c-9b80-85cc8efc9897')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-801c4c0d-d89b-4b5c-9b80-85cc8efc9897 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-801c4c0d-d89b-4b5c-9b80-85cc8efc9897');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can write some code to visualize the sample text, truth label, prediction class and prediction probability. Because we've sorted our samples by prediction probability, viewing samples from the head of our most_wrong DataFrame will show us false positives."
      ],
      "metadata": {
        "id": "OLDzFYPTJ9IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMpsEIQMKK_E",
        "outputId": "35c3c48a-183f-45b6-8a2b-afb3c416f35b"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.5472635626792908\n",
            "Text:\n",
            "Crackdown 3 Destruction Restricted to Multiplayer: Crackdown 3 impressed earlier this week with a demonstratio... http://t.co/gwESgesZxV\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.5451317429542542\n",
            "Text:\n",
            "Crackdown 3 Destruction Restricted to Multiplayer: Crackdown 3 impressed earlier this week with a demonstratio... http://t.co/LMWKjsYCgj\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.5444976091384888\n",
            "Text:\n",
            "Wrinkled the face of deluge as decayed;\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.5437787771224976\n",
            "Text:\n",
            "Untangle yourself from requiring your partner to fill your needs and how to love without fear #BestTalkRadio Listen http://t.co/8j09ZUTxWT\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.5417109131813049\n",
            "Text:\n",
            "A change in the State fire code prohibits grills on decks at condos and apartment buildings.  Check with your... http://t.co/KE1ZS6NAml\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.539081335067749\n",
            "Text:\n",
            "#ArrestpastorNganga it so worrying 2 see how some police officers in Kenya have sunk to low to the point of collaborating with pick pockets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.5380706191062927\n",
            "Text:\n",
            "Enugu Government to demolish illegal structures at International Conference Centre: Enugu State government app... http://t.co/MsKn6D3eKH\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.5372014045715332\n",
            "Text:\n",
            "Armageddon averted by El Patron\n",
            "#UltimaLucha\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.5366703867912292\n",
            "Text:\n",
            "Your PSA for the day: If a fire truck is behind you with lights going MOVE OVER!!! so they can get to their call.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.5364659428596497\n",
            "Text:\n",
            "@almusafirah_ you feel trapped innit ??\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je3TXbsNKSFv",
        "outputId": "6eb1c1ed-84ce-4e87-c8e6-bdd2cddaaf3a"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0, Prob: 0.4887546896934509\n",
            "Text:\n",
            "First time getting into #gbbo2015 and physically gasped at the cake 'mudslide' incident already way too emotionally invested...\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.48840588331222534\n",
            "Text:\n",
            "@KlaraJoelsson Well I have seen it now! That's a bummer. We've had this heat wave tho... 43'c!! I'd prefer the rain... :P\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.4868015944957733\n",
            "Text:\n",
            "Leitchfield KY:\n",
            "\n",
            " Bella Edward &amp; Rosalie need rescue/adoption/local foster home(s)/sponsorships.\n",
            "\n",
            " Trapped &amp;... http://t.co/Ajay0sNPlg\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.4865732192993164\n",
            "Text:\n",
            "Sadly before she could save humanity Ursula drowned in the drool of a protoshoggoth but at least she sort of died doing what she loved.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.4843946099281311\n",
            "Text:\n",
            "A Dayton-area org tells me it was hit by a cyber attack: http://t.co/7LhKJz0IVO\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.48165249824523926\n",
            "Text:\n",
            "MEG issues Hazardous Weather Outlook (HWO) http://t.co/3X6RBQJHn3\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.48161497712135315\n",
            "Text:\n",
            "DireTube Information ÛÒ Egypt Cyprus and Greece agreed to fightåÊterrorism http://t.co/V6IjxCCD2I http://t.co/YSXhFWMGOD\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.4803556501865387\n",
            "Text:\n",
            "@Zak_Bagans this is Sabrina my dad rescued her from some dude who kept her in a cage. We've had her since I was 4 http://t.co/1k2PhQcuW8\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.4790790379047394\n",
            "Text:\n",
            "@emmerdale can we have a public vote for the next annual village disaster?  i want an isis strike or a nuclear accident &amp; end this forever\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.47191211581230164\n",
            "Text:\n",
            "Dr. Owen says four of Ferrell's ten bullet wounds were 'rapidly lethal' #KerrickTrial #TWCNewsCLT http://t.co/nNBEXhKlHr\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on the test dataset"
      ],
      "metadata": {
        "id": "fAZlejyUKaH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Making predictions on the test dataset\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i8-YJpuKqJU",
        "outputId": "c93376c0-a0b9-45ed-cf09-d233d3a67930"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1, Prob: 0.5115919709205627\n",
            "Text:\n",
            "??Water fight??\n",
            "Penn park 6pm \n",
            "      BYOW\n",
            "(Bring Your Own Weapons)\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.49229469895362854\n",
            "Text:\n",
            "Audio: Listen/purchase: Detonate (feat. M.O.P.) by Apollo Brown http://t.co/6ZSWtoKsif\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.504982590675354\n",
            "Text:\n",
            "@dmon2112 @C_T_Morgan but the fire rings of NYC permits I'd have to jump through for a food truck don't make it appealing\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.5138631463050842\n",
            "Text:\n",
            "Love wounds\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.5242616534233093\n",
            "Text:\n",
            "@MattBuek Some pitchers gracefully lose their stuff. Some fall off a cliff and land on their throwing arm. Hard to tell who gets what.\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.49293631315231323\n",
            "Text:\n",
            "The revival of Cyclone Football begins today!!  Be there September 5th!!\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.5040991306304932\n",
            "Text:\n",
            "@HusnaaVhora I hope they dust off the air raid sirens! You can quote me on that lol\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.5163061618804932\n",
            "Text:\n",
            "Pak army helicopter crashed in Mansehra. \n",
            "Pray for departed souls. http://t.co/XclNBVvfSi\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.5152174234390259\n",
            "Text:\n",
            "South Side factory where worker electrocuted pays $17000 penalty http://t.co/PENJHc4ZCx #Columbus #Ohio #news\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.5116423964500427\n",
            "Text:\n",
            "PSA- I chopped 3 #jalapenos &amp; my fingers were burning-lava-on-fire painful for 5+ hrs. This is a first! Wear gloves! #peppers from #hell.\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Predicting on Tweets from the wild"
      ],
      "metadata": {
        "id": "pthHyDG9Kq5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Turn Tweet into string\n",
        "daniels_tweet = \"Life like an ensemble: take the best choices from others and make your own\""
      ],
      "metadata": {
        "id": "aWG6p0G8KzKX"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_sentence(model, sentence):\n",
        "  \"\"\"\n",
        "  Uses model to make a prediction on sentence.\n",
        "\n",
        "  Returns the sentence, the predicted label and the prediction probability.\n",
        "  \"\"\"\n",
        "  pred_prob = model.predict([sentence])\n",
        "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
        "  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sentence}\")"
      ],
      "metadata": {
        "id": "CbllviOIK7VQ"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on Tweet from the wild\n",
        "predict_on_sentence(model=model_6, # use the USE model\n",
        "                    sentence=daniels_tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQMsuOWPLAfQ",
        "outputId": "8b15e9db-2e3c-4bef-934e-316b23ce670e"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.5110728740692139\n",
            "Text:\n",
            "Life like an ensemble: take the best choices from others and make your own\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woohoo! Our model predicted correctly. My Tweet wasn't about a diaster.\n",
        "\n",
        "How about we find a few Tweets about actual diasters?\n",
        "\n",
        "Such as the following two Tweets about the 2020 Beirut explosions."
      ],
      "metadata": {
        "id": "GX9ERTqULEBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Source - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n",
        "beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
        "\n",
        "# Source - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n",
        "beirut_tweet_2 = \"#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\""
      ],
      "metadata": {
        "id": "KbwzWNvuLMx3"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predict on diaster Tweet 1\n",
        "predict_on_sentence(model=model_6, \n",
        "                    sentence=beirut_tweet_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukXCnnd_LNXw",
        "outputId": "11ac0c5f-a61f-40b6-8fb5-d807901ad4ba"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.5291858315467834\n",
            "Text:\n",
            "Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predict on diaster Tweet 2\n",
        "predict_on_sentence(model=model_6, \n",
        "                    sentence=beirut_tweet_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-hEBRYwLPt5",
        "outputId": "36da59b6-8e56-460c-c602-523b745b8c0f"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.5065233707427979\n",
            "Text:\n",
            "#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our model is performing as expected, predicting both of the diaster Tweets as actual diasters.\n",
        "\n",
        "🔑 Note: The above examples are cherry-picked and are cases where you'd expect a model to function at high performance. For actual production systems, you'll want to continaully perform tests to see how your model is performing."
      ],
      "metadata": {
        "id": "1QkOlWBgLSgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The speed/score tradeoff"
      ],
      "metadata": {
        "id": "1_aTdyJfLbRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the final tests we're going to do is to find the speed/score tradeoffs between our best model and baseline model.\n",
        "\n",
        "Why is this important?\n",
        "\n",
        "Although it can be tempting to just choose the best performing model you find through experimentation, this model might not actually work in a production setting.\n",
        "\n",
        "Put it this way, imagine you're Twitter and receive 1 million Tweets per hour (this is a made up number, the actual number is much higher). And you're trying to build a diaster detection system to read Tweets and alert authorities with details about a diaster in close to real-time.\n",
        "\n",
        "Compute power isn't free so you're limited to a single compute machine for the project. On that machine, one of your models makes 10,000 predictions per second at 80% accuracy where as another one of your models (a larger model) makes 100 predictions per second at 85% accuracy.\n",
        "\n",
        "Which model do you choose?\n",
        "\n",
        "Is the second model's performance boost worth missing out on the extra capacity?\n",
        "\n",
        "Of course, there are many options you could try here, such as sending as many Tweets as possible to the first model and then sending the ones which the model is least certain of to the second model.\n",
        "\n",
        "The point here is to illustrate the best model you find through experimentation, might not be the model you end up using in production.\n",
        "\n",
        "To make this more concrete, let's write a function to take a model and a number of samples and time how long the given model takes to make predictions on those samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "CA1QVqSTLrDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the time of predictions\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \n",
        "  Args:\n",
        "  ----\n",
        "  model = a trained model\n",
        "  sample = a list of samples\n",
        "\n",
        "  Returns:\n",
        "  ----\n",
        "  total_time = total elapsed time for model to make predictions on samples\n",
        "  time_per_pred = time in seconds per single sample\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time-start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(val_sentences) # find prediction time per sample\n",
        "  return total_time, time_per_pred"
      ],
      "metadata": {
        "id": "Vg4m3OjwL9nc"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TF Hub Sentence Encoder prediction times\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xCYhdbrL-9T",
        "outputId": "0dcbe0d2-ac90-4cfa-b566-b1a3459fcfe4"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4095418160004556, 0.0005374564514441674)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Naive Bayes prediction times\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVlbHsgZMBmN",
        "outputId": "cc50fef2-314a-49aa-f7bf-66efc977965d"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.027831357000650314, 3.652409055203453e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems with our current hardware (in my case, I'm using a Google Colab notebook) our best performing model takes over 10x the time to make predictions as our baseline model.\n",
        "\n",
        "Is that extra prediction time worth it?\n",
        "\n",
        "Let's compare time per prediction versus our model's F1-scores."
      ],
      "metadata": {
        "id": "k0TI1S2TME-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-Score\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "hemLNlxOMJig",
        "outputId": "9d9c0813-71d1-462f-b4ea-5c6b06767bf5"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, the ideal position for each of these dots is to be in the top left of the plot (low time per prediction, high F1-score).\n",
        "\n",
        "In our case, there's a clear tradeoff for time per prediction and performance. Our best performing model takes an order of magnitude longer per prediction but only results in a few F1-score point increase.\n",
        "\n",
        "This kind of tradeoff is something you'll need to keep in mind when incorporating machine learning models into your own applications."
      ],
      "metadata": {
        "id": "Ax5VqlCYMOHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3WoTAfczMY48"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}